{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Motion\n",
    "\n",
    "Welcome to JetBot's browser based programming interface!  This document is\n",
    "called a *Jupyter Notebook*, which combines text, code, and graphic\n",
    "display all in one!  Pretty neat, huh? If you're unfamiliar with *Jupyter* we suggest clicking the \n",
    "``Help`` drop down menu in the top toolbar.  This has useful references for\n",
    "programming with *Jupyter*. \n",
    "\n",
    "In this notebook, we'll cover the basics of controlling JetBot. \n",
    "\n",
    "### Importing the Robot class\n",
    "\n",
    "To get started programming JetBot, we'll need to import the ``Robot`` class.  This class\n",
    "allows us to easily control the robot's motors!  This is contained in the ``jetbot`` package.\n",
    "\n",
    "> If you're new to Python, a *package* is essentially a folder containing \n",
    "> code files.  These code files are called *modules*.\n",
    "\n",
    "To import the ``Robot`` class, highlight the cell below and press ``ctrl + enter`` or the ``play`` icon above.\n",
    "This will execute the code contained in the cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jetbot import Robot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've imported the ``Robot`` class we can initialize the class *instance* as follows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "robot = Robot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Commanding the robot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've created our ``Robot`` instance we named \"robot\", we can use this instance\n",
    "to control the robot.  To make the robot spin counterclockwise at 30% of it's max speed\n",
    "we can call the following\n",
    "\n",
    "> WARNING:  This next command will make the robot move!  Please make sure the robot has clearance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "robot.left(speed=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool, you should see the robot spin counterclockwise!\n",
    "\n",
    "> If your robot didn't turn left, that means one of the motors is wired backwards!  Try powering down your\n",
    "> robot and swapping the terminals that the ``red`` and ``black`` cables of the incorrect motor.\n",
    "> \n",
    "> REMINDER: Always be careful to check your wiring, and don't change the wiring on a running system!\n",
    "\n",
    "Now, to stop the robot you can call the ``stop`` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "robot.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maybe we only want to run the robot for a set period of time.  For that, we can use the Python ``time`` package.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This package defines the ``sleep`` function, which causes the code execution to block for the specified number of seconds\n",
    "before running the next command.  Try the following to make the robot turn left only for half a second."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "robot.left(0.3)\n",
    "time.sleep(0.5)\n",
    "robot.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great.  You should see the robot turn left for a bit and then stop.\n",
    "\n",
    "> Wondering what happened to the ``speed=`` inside the ``left`` method?  Python allows \n",
    "> us to set function parameters by either their name, or the order that they are defined\n",
    "> (without specifying the name).\n",
    "\n",
    "The ``BasicJetbot`` class also has the methods ``right``, ``forward``, and ``backward``.  Try creating your own cell to make\n",
    "the robot move forward at 50% speed for one second.\n",
    "\n",
    "Create a new cell by highlighting an existing cell and pressing ``b`` or the ``+`` icon above.  Once you've done that, type in the code that you think will make the robot move forward at 50% speed for one second."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Controlling motors individually\n",
    "\n",
    "Above we saw how we can control the robot using commands like ``left``, ``right``, etc.  But what if we want to set each motor speed \n",
    "individually?  Well, there are two ways you can do this\n",
    "\n",
    "The first way is to call the ``set_motors`` method.  For example, to turn along a left arch for a second we could set the left motor to 30% and the right motor to 60% like follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "robot.set_motors(0.3, 0.6)\n",
    "time.sleep(1.0)\n",
    "robot.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great!  You should see the robot move along a left arch.  But actually, there's another way that we could accomplish the same thing.\n",
    "\n",
    "The ``Robot`` class has two attributes named ``left_motor`` and ``right_motor`` that represent each motor individually.\n",
    "These attributes are ``Motor`` class instances, each which contains a ``value`` attribute.  This ``value`` attribute\n",
    "is a [traitlet](https://github.com/ipython/traitlets) which generates ``events`` when assigned a new value.  In the motor\n",
    "class, we attach a function that updates the motor commands whenever the value changes.\n",
    "\n",
    "So, to accomplish the exact same thing we did above, we could execute the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "robot.left_motor.value = 0.3\n",
    "robot.right_motor.value = 0.6\n",
    "time.sleep(1.0)\n",
    "robot.left_motor.value = 0.0\n",
    "robot.right_motor.value = 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see the robot move in the same exact way!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Link motors to traitlets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A really cool feature about these [traitlets](https://github.com/ipython/traitlets) is that we can \n",
    "also link them to other traitlets!  This is super handy because Jupyter Notebooks allow us\n",
    "to make graphical ``widgets`` that use traitlets under the hood.  This means we can attach\n",
    "our motors to ``widgets`` to control them from the browser, or just visualize the value.\n",
    "\n",
    "To show how to do this, let's create and display two sliders that we'll use to control our motors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets.widgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "# create two sliders with range [-1.0, 1.0]\n",
    "left_slider = widgets.FloatSlider(description='left', min=-1.0, max=1.0, step=0.01, orientation='vertical')\n",
    "right_slider = widgets.FloatSlider(description='right', min=-1.0, max=1.0, step=0.01, orientation='vertical')\n",
    "\n",
    "# create a horizontal box container to place the sliders next to each other\n",
    "slider_container = widgets.HBox([left_slider, right_slider])\n",
    "\n",
    "# display the container in this cell's output\n",
    "display(slider_container)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see two ``vertical`` sliders displayed above. \n",
    "\n",
    "> HELPFUL TIP:  In Jupyter Lab, you can actually \"pop\" the output of cells into entirely separate window!  It will still be \n",
    "> connected to the notebook, but displayed separately.  This is helpful if we want to pin the output of code we executed elsewhere.\n",
    "> To do this, right click the output of the cell and select ``Create New View for Output``.  You can then drag the new window\n",
    "> to a location you find pleasing.\n",
    "\n",
    "Try clicking and dragging the sliders up and down.  Notice nothing happens when we move the sliders currently.  That's because we haven't connected them to motors yet!  We'll do that by using the ``link`` function from the traitlets package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import traitlets\n",
    "\n",
    "left_link = traitlets.link((left_slider, 'value'), (robot.left_motor, 'value'))\n",
    "right_link = traitlets.link((right_slider, 'value'), (robot.right_motor, 'value'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now try dragging the sliders (slowly at first).  You should see the respective motor turn!\n",
    "\n",
    "The ``link`` function that we created above actually creates a bi-directional link!  That means,\n",
    "if we set the motor values elsewhere, the sliders will update!  Try executing the code block below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "robot.forward(0.3)\n",
    "time.sleep(1.0)\n",
    "robot.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see the sliders respond to the motor commands!  If we want to remove this connection we can call the\n",
    "``unlink`` method of each link."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_link.unlink()\n",
    "right_link.unlink()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But what if we don't want a *bi-directional* link, let's say we only want to use the sliders to display the motor values,\n",
    "but not control them.  For that we can use the ``dlink`` function.  The left input is the ``source`` and the right input is the ``target``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_link = traitlets.dlink((robot.left_motor, 'value'), (left_slider, 'value'))\n",
    "right_link = traitlets.dlink((robot.right_motor, 'value'), (right_slider, 'value'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now try moving the sliders.  You should see that the robot doesn't respond.  But when set the motors using a different method,\n",
    "the sliders will update and display the value!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attach functions to events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to use traitlets, is by attaching functions (like ``forward``) to events.  These\n",
    "functions will get called whenever a change to the object occurs, and will be passed some information about that change\n",
    "like the ``old`` value and the ``new`` value.  \n",
    "\n",
    "Let's create and display some buttons that we'll use to control the robot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create buttons\n",
    "button_layout = widgets.Layout(width='100px', height='80px', align_self='center')\n",
    "stop_button = widgets.Button(description='stop', button_style='danger', layout=button_layout)\n",
    "forward_button = widgets.Button(description='forward', layout=button_layout)\n",
    "backward_button = widgets.Button(description='backward', layout=button_layout)\n",
    "left_button = widgets.Button(description='left', layout=button_layout)\n",
    "right_button = widgets.Button(description='right', layout=button_layout)\n",
    "\n",
    "# display buttons\n",
    "middle_box = widgets.HBox([left_button, stop_button, right_button], layout=widgets.Layout(align_self='center'))\n",
    "controls_box = widgets.VBox([forward_button, middle_box, backward_button])\n",
    "display(controls_box)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see a set of robot controls displayed above!  But right now they wont do anything.  To do that\n",
    "we'll need to create some functions that we'll attach to the button's ``on_click`` event.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stop(change):\n",
    "    robot.stop()\n",
    "    \n",
    "def step_forward(change):\n",
    "    robot.forward(0.4)\n",
    "    time.sleep(0.5)\n",
    "    robot.stop()\n",
    "\n",
    "def step_backward(change):\n",
    "    robot.backward(0.4)\n",
    "    time.sleep(0.5)\n",
    "    robot.stop()\n",
    "\n",
    "def step_left(change):\n",
    "    robot.left(0.3)\n",
    "    time.sleep(0.5)\n",
    "    robot.stop()\n",
    "\n",
    "def step_right(change):\n",
    "    robot.right(0.3)\n",
    "    time.sleep(0.5)\n",
    "    robot.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've defined the functions, let's attach them to the on-click events of each button"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# link buttons to actions\n",
    "stop_button.on_click(stop)\n",
    "forward_button.on_click(step_forward)\n",
    "backward_button.on_click(step_backward)\n",
    "left_button.on_click(step_left)\n",
    "right_button.on_click(step_right)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now when you click each button, you should see the robot move!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heartbeat Killswitch\n",
    "\n",
    "Here we show how to connect a 'heartbeat' to stop the robot from moving.  This is a simple way to detect if the robot connection is alive.  You can lower the slider below to reduce the period (in seconds) of the heartbeat.  If a round-trip communication between browser cannot be made within two heartbeats, the '`status`' attribute of the heartbeat will be set ``dead``.  As soon as the connection is restored, the ``status`` attribute will return to ``alive``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jetbot import Heartbeat\n",
    "\n",
    "heartbeat = Heartbeat()\n",
    "\n",
    "# this function will be called when heartbeat 'alive' status changes\n",
    "def handle_heartbeat_status(change):\n",
    "    if change['new'] == Heartbeat.Status.dead:\n",
    "        robot.stop()\n",
    "        \n",
    "heartbeat.observe(handle_heartbeat_status, names='status')\n",
    "\n",
    "period_slider = widgets.FloatSlider(description='period', min=0.001, max=0.5, step=0.01, value=0.5)\n",
    "traitlets.dlink((period_slider, 'value'), (heartbeat, 'period'))\n",
    "\n",
    "display(period_slider, heartbeat.pulseout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try executing the code below to start the motors, and then lower the slider to see what happens.  You can also try disconnecting your robot or PC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "robot.left(0.2) \n",
    "\n",
    "# now lower the `period` slider above until the network heartbeat can't be satisfied"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "That's it for this example notebook!  Hopefully you feel confident that you can program your robot to move around now :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--device DEVICE] [--width WIDTH] [--height HEIGHT] [--use_static_image_mode] [--min_detection_confidence MIN_DETECTION_CONFIDENCE] [--min_tracking_confidence MIN_TRACKING_CONFIDENCE]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f C:\\Users\\lpzan\\AppData\\Roaming\\jupyter\\runtime\\kernel-8621e5cf-17ed-4e25-9230-4398652b503a.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import copy\n",
    "import argparse\n",
    "import itertools\n",
    "from collections import Counter\n",
    "from collections import deque\n",
    "\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "\n",
    "from utils import CvFpsCalc\n",
    "from model import KeyPointClassifier\n",
    "from model import PointHistoryClassifier\n",
    "\n",
    "\n",
    "def get_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    parser.add_argument(\"--device\", type=int, default=0)\n",
    "    parser.add_argument(\"--width\", help='cap width', type=int, default=1920)\n",
    "    parser.add_argument(\"--height\", help='cap height', type=int, default=1080)\n",
    "\n",
    "    parser.add_argument('--use_static_image_mode', action='store_true')\n",
    "    parser.add_argument(\"--min_detection_confidence\",\n",
    "                        help='min_detection_confidence',\n",
    "                        type=float,\n",
    "                        default=0.7)\n",
    "    parser.add_argument(\"--min_tracking_confidence\",\n",
    "                        help='min_tracking_confidence',\n",
    "                        type=int,\n",
    "                        default=0.5)\n",
    "\n",
    "    #args = parser.parse_args()\n",
    "\n",
    "    return parser.parse_args(\"\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    args = get_args() #Gets - device(int), width(int), height(int), use_static_image_mode(string), min_detection_confidence(float), min_tracking_confidence(float)\n",
    "\n",
    "    cap_device = args.device \n",
    "    cap_width = args.width\n",
    "    cap_height = args.height\n",
    "\n",
    "    use_static_image_mode = args.use_static_image_mode\n",
    "    min_detection_confidence = args.min_detection_confidence\n",
    "    min_tracking_confidence = args.min_tracking_confidence\n",
    "\n",
    "    use_brect = False #Used for bounding Rectangle\n",
    "\n",
    "    # Camera preparation ###############################################################\n",
    "    cap = cv.VideoCapture(cap_device)\n",
    "    cap.set(cv.CAP_PROP_FRAME_WIDTH, cap_width)\n",
    "    cap.set(cv.CAP_PROP_FRAME_HEIGHT, cap_height)\n",
    "\n",
    "    # Model load #############################################################\n",
    "    mp_hands = mp.solutions.hands\n",
    "    hands = mp_hands.Hands(\n",
    "        static_image_mode=use_static_image_mode,\n",
    "        max_num_hands=2,\n",
    "        min_detection_confidence=min_detection_confidence,\n",
    "        min_tracking_confidence=min_tracking_confidence,\n",
    "    )\n",
    "\n",
    "    keypoint_classifier = KeyPointClassifier()\n",
    "\n",
    "    point_history_classifier = PointHistoryClassifier()\n",
    "\n",
    "    # Read labels ###########################################################\n",
    "    with open('model/keypoint_classifier/keypoint_classifier_label.csv',\n",
    "              encoding='utf-8-sig') as f:\n",
    "        keypoint_classifier_labels = csv.reader(f)\n",
    "        keypoint_classifier_labels = [\n",
    "            row[0] for row in keypoint_classifier_labels\n",
    "        ]\n",
    "    with open(\n",
    "            'model/point_history_classifier/point_history_classifier_label.csv',\n",
    "            encoding='utf-8-sig') as f:\n",
    "        point_history_classifier_labels = csv.reader(f)\n",
    "        point_history_classifier_labels = [\n",
    "            row[0] for row in point_history_classifier_labels\n",
    "        ]\n",
    "\n",
    "    # FPS Measurement ########################################################\n",
    "    cvFpsCalc = CvFpsCalc(buffer_len=10)\n",
    "\n",
    "    # Coordinate history #################################################################\n",
    "    history_length = 16\n",
    "    point_history = deque(maxlen=history_length)\n",
    "\n",
    "    # Finger gesture history ################################################\n",
    "    finger_gesture_history = deque(maxlen=history_length)\n",
    "\n",
    "    #  ########################################################################\n",
    "    mode = 0\n",
    "\n",
    "    while True:\n",
    "        fps = cvFpsCalc.get() #Shows FPS\n",
    "\n",
    "        # Process Key (ESC: end) #################################################\n",
    "        key = cv.waitKey(5) #Adds Delay to while loop\n",
    "        if key == 27:  # ESC\n",
    "            break\n",
    "        number, mode = select_mode(key, mode)\n",
    "\n",
    "        # Camera capture #####################################################\n",
    "        ret, image = cap.read() #Ret will be True of false, image is each frame\n",
    "        if not ret:\n",
    "            break\n",
    "        image = cv.flip(image, 1)  # Mirror display\n",
    "        debug_image = copy.deepcopy(image)\n",
    "\n",
    "        # Detection implementation #############################################################\n",
    "        image = cv.cvtColor(image, cv.COLOR_BGR2RGB)\n",
    "\n",
    "        image.flags.writeable = False\n",
    "        results = hands.process(image)\n",
    "        image.flags.writeable = True\n",
    "\n",
    "        #  ####################################################################\n",
    "        if results.multi_hand_landmarks is not None:\n",
    "            for hand_landmarks, handedness in zip(results.multi_hand_landmarks,\n",
    "                                                  results.multi_handedness):\n",
    "\n",
    "                #IMPLEMENT MOVEMENT HERE\n",
    "\n",
    "                # Bounding box calculation\n",
    "                brect = calc_bounding_rect(debug_image, hand_landmarks)\n",
    "                # Landmark calculation\n",
    "                landmark_list = calc_landmark_list(debug_image, hand_landmarks)\n",
    "\n",
    "                # Conversion to relative coordinates / normalized coordinates\n",
    "                pre_processed_landmark_list = pre_process_landmark(\n",
    "                    landmark_list)\n",
    "                pre_processed_point_history_list = pre_process_point_history(\n",
    "                    debug_image, point_history)\n",
    "                # Write to the dataset file\n",
    "                logging_csv(number, mode, pre_processed_landmark_list,\n",
    "                            pre_processed_point_history_list)\n",
    "\n",
    "                # Hand sign classification\n",
    "                hand_sign_id = keypoint_classifier(pre_processed_landmark_list)\n",
    "\n",
    "                #ROBOT CONTROLS\n",
    "                if hand_sign_id==0:\n",
    "                    print(\"R up\")\n",
    "                    #robot.right_motor.value = 0.3\n",
    "                elif hand_sign_id==1:\n",
    "                    print(\"R down\")\n",
    "                    #robot.right_motor.value = 0.3\n",
    "                elif hand_sign_id==2:\n",
    "                    print(\"L up\")\n",
    "                    #robot.left_motor.value = 0.3\n",
    "                elif hand_sign_id==3:\n",
    "                    print(\"L down\")\n",
    "                    #robot.left_motor.value = -0.3\n",
    "                elif hand_sign_id==4:\n",
    "                    print(\"Open\")\n",
    "                elif hand_sign_id==5:\n",
    "                    print(\"Close\")\n",
    "                elif hand_sign_id==6:\n",
    "                    print(\"\")\n",
    "                elif hand_sign_id==7:\n",
    "                    print(\"\")\n",
    "                elif hand_sign_id==8:\n",
    "                    print(\"\")\n",
    "                elif hand_sign_id==9:\n",
    "                    print(\"\")\n",
    "                print(\"stop\")\n",
    "                #robot.left_motor.value = 0.0\n",
    "                #robot.right_motor.value = 0.0\n",
    "\n",
    "\n",
    "                if hand_sign_id == \"Not Applicable\":  # Point gesture (Change to 2 for reactivation)\n",
    "                    point_history.append(landmark_list[8])\n",
    "                else:\n",
    "                    point_history.append([0, 0])\n",
    "\n",
    "                # Finger gesture classification\n",
    "                finger_gesture_id = 0\n",
    "                point_history_len = len(pre_processed_point_history_list)\n",
    "                if point_history_len == (history_length * 2):\n",
    "                    finger_gesture_id = point_history_classifier(\n",
    "                        pre_processed_point_history_list)\n",
    "\n",
    "                # Calculates the gesture IDs in the latest detection\n",
    "                finger_gesture_history.append(finger_gesture_id)\n",
    "                most_common_fg_id = Counter(\n",
    "                    finger_gesture_history).most_common()\n",
    "\n",
    "                # Drawing part\n",
    "                debug_image = draw_bounding_rect(use_brect, debug_image, brect)\n",
    "                debug_image = draw_landmarks(debug_image, landmark_list)\n",
    "                debug_image = draw_info_text(\n",
    "                    debug_image,\n",
    "                    brect,\n",
    "                    handedness,\n",
    "                    keypoint_classifier_labels[hand_sign_id],\n",
    "                    point_history_classifier_labels[most_common_fg_id[0][0]],\n",
    "                )\n",
    "        else:\n",
    "            point_history.append([0, 0])\n",
    "\n",
    "        debug_image = draw_point_history(debug_image, point_history)\n",
    "        debug_image = draw_info(debug_image, fps, mode, number)\n",
    "\n",
    "        # Screen reflection #############################################################\n",
    "        cv.imshow('Hand Gesture Recognition', debug_image)\n",
    "\n",
    "    cap.release()\n",
    "    cv.destroyAllWindows()\n",
    "\n",
    "\n",
    "#This Function is used for adding new Keypoints\n",
    "def select_mode(key, mode):\n",
    "    number = -1\n",
    "    if 48 <= key <= 57:  # 0 ~ 9\n",
    "        number = key - 48\n",
    "    if key == 110:  # n\n",
    "        mode = 0\n",
    "    if key == 107:  # k\n",
    "        mode = 1\n",
    "    if key == 104:  # h\n",
    "        mode = 2\n",
    "    return number, mode\n",
    "\n",
    "\n",
    "def calc_bounding_rect(image, landmarks):\n",
    "    image_width, image_height = image.shape[1], image.shape[0]\n",
    "\n",
    "    landmark_array = np.empty((0, 2), int)\n",
    "\n",
    "    for _, landmark in enumerate(landmarks.landmark):\n",
    "        landmark_x = min(int(landmark.x * image_width), image_width - 1)\n",
    "        landmark_y = min(int(landmark.y * image_height), image_height - 1)\n",
    "\n",
    "        landmark_point = [np.array((landmark_x, landmark_y))]\n",
    "\n",
    "        landmark_array = np.append(landmark_array, landmark_point, axis=0)\n",
    "\n",
    "    x, y, w, h = cv.boundingRect(landmark_array)\n",
    "\n",
    "    return [x, y, x + w, y + h]\n",
    "\n",
    "\n",
    "def calc_landmark_list(image, landmarks):\n",
    "    image_width, image_height = image.shape[1], image.shape[0]\n",
    "\n",
    "    landmark_point = []\n",
    "\n",
    "    # Keypoint\n",
    "    for _, landmark in enumerate(landmarks.landmark):\n",
    "        landmark_x = min(int(landmark.x * image_width), image_width - 1)\n",
    "        landmark_y = min(int(landmark.y * image_height), image_height - 1)\n",
    "        # landmark_z = landmark.z\n",
    "\n",
    "        landmark_point.append([landmark_x, landmark_y])\n",
    "\n",
    "    return landmark_point\n",
    "\n",
    "\n",
    "def pre_process_landmark(landmark_list):\n",
    "    temp_landmark_list = copy.deepcopy(landmark_list)\n",
    "\n",
    "    # Convert to relative coordinates\n",
    "    base_x, base_y = 0, 0\n",
    "    for index, landmark_point in enumerate(temp_landmark_list):\n",
    "        if index == 0:\n",
    "            base_x, base_y = landmark_point[0], landmark_point[1]\n",
    "\n",
    "        temp_landmark_list[index][0] = temp_landmark_list[index][0] - base_x\n",
    "        temp_landmark_list[index][1] = temp_landmark_list[index][1] - base_y\n",
    "\n",
    "    # Convert to a one-dimensional list\n",
    "    temp_landmark_list = list(\n",
    "        itertools.chain.from_iterable(temp_landmark_list))\n",
    "\n",
    "    # Normalization\n",
    "    max_value = max(list(map(abs, temp_landmark_list)))\n",
    "\n",
    "    def normalize_(n):\n",
    "        return n / max_value\n",
    "\n",
    "    temp_landmark_list = list(map(normalize_, temp_landmark_list))\n",
    "\n",
    "    return temp_landmark_list\n",
    "\n",
    "\n",
    "def pre_process_point_history(image, point_history):\n",
    "    image_width, image_height = image.shape[1], image.shape[0]\n",
    "\n",
    "    temp_point_history = copy.deepcopy(point_history)\n",
    "\n",
    "    # Convert to relative coordinates\n",
    "    base_x, base_y = 0, 0\n",
    "    for index, point in enumerate(temp_point_history):\n",
    "        if index == 0:\n",
    "            base_x, base_y = point[0], point[1]\n",
    "\n",
    "        temp_point_history[index][0] = (temp_point_history[index][0] -\n",
    "                                        base_x) / image_width\n",
    "        temp_point_history[index][1] = (temp_point_history[index][1] -\n",
    "                                        base_y) / image_height\n",
    "\n",
    "    # Convert to a one-dimensional list\n",
    "    temp_point_history = list(\n",
    "        itertools.chain.from_iterable(temp_point_history))\n",
    "\n",
    "    return temp_point_history\n",
    "\n",
    "\n",
    "def logging_csv(number, mode, landmark_list, point_history_list):\n",
    "    if mode == 0:\n",
    "        pass\n",
    "    if mode == 1 and (0 <= number <= 9):\n",
    "        csv_path = 'model/keypoint_classifier/keypoint.csv'\n",
    "        with open(csv_path, 'a', newline=\"\") as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow([number, *landmark_list])\n",
    "    if mode == 2 and (0 <= number <= 9):\n",
    "        csv_path = 'model/point_history_classifier/point_history.csv'\n",
    "        with open(csv_path, 'a', newline=\"\") as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow([number, *point_history_list])\n",
    "    return\n",
    "\n",
    "\n",
    "def draw_landmarks(image, landmark_point):\n",
    "    if len(landmark_point) > 0:\n",
    "        # Thumb\n",
    "        cv.line(image, tuple(landmark_point[2]), tuple(landmark_point[3]),\n",
    "                (0, 0, 0), 6)\n",
    "        cv.line(image, tuple(landmark_point[2]), tuple(landmark_point[3]),\n",
    "                (255, 255, 255), 2)\n",
    "        cv.line(image, tuple(landmark_point[3]), tuple(landmark_point[4]),\n",
    "                (0, 0, 0), 6)\n",
    "        cv.line(image, tuple(landmark_point[3]), tuple(landmark_point[4]),\n",
    "                (255, 255, 255), 2)\n",
    "\n",
    "        # Index finger\n",
    "        cv.line(image, tuple(landmark_point[5]), tuple(landmark_point[6]),\n",
    "                (0, 0, 0), 6)\n",
    "        cv.line(image, tuple(landmark_point[5]), tuple(landmark_point[6]),\n",
    "                (255, 255, 255), 2)\n",
    "        cv.line(image, tuple(landmark_point[6]), tuple(landmark_point[7]),\n",
    "                (0, 0, 0), 6)\n",
    "        cv.line(image, tuple(landmark_point[6]), tuple(landmark_point[7]),\n",
    "                (255, 255, 255), 2)\n",
    "        cv.line(image, tuple(landmark_point[7]), tuple(landmark_point[8]),\n",
    "                (0, 0, 0), 6)\n",
    "        cv.line(image, tuple(landmark_point[7]), tuple(landmark_point[8]),\n",
    "                (255, 255, 255), 2)\n",
    "\n",
    "        # Middle finger\n",
    "        cv.line(image, tuple(landmark_point[9]), tuple(landmark_point[10]),\n",
    "                (0, 0, 0), 6)\n",
    "        cv.line(image, tuple(landmark_point[9]), tuple(landmark_point[10]),\n",
    "                (255, 255, 255), 2)\n",
    "        cv.line(image, tuple(landmark_point[10]), tuple(landmark_point[11]),\n",
    "                (0, 0, 0), 6)\n",
    "        cv.line(image, tuple(landmark_point[10]), tuple(landmark_point[11]),\n",
    "                (255, 255, 255), 2)\n",
    "        cv.line(image, tuple(landmark_point[11]), tuple(landmark_point[12]),\n",
    "                (0, 0, 0), 6)\n",
    "        cv.line(image, tuple(landmark_point[11]), tuple(landmark_point[12]),\n",
    "                (255, 255, 255), 2)\n",
    "\n",
    "        # Ring finger\n",
    "        cv.line(image, tuple(landmark_point[13]), tuple(landmark_point[14]),\n",
    "                (0, 0, 0), 6)\n",
    "        cv.line(image, tuple(landmark_point[13]), tuple(landmark_point[14]),\n",
    "                (255, 255, 255), 2)\n",
    "        cv.line(image, tuple(landmark_point[14]), tuple(landmark_point[15]),\n",
    "                (0, 0, 0), 6)\n",
    "        cv.line(image, tuple(landmark_point[14]), tuple(landmark_point[15]),\n",
    "                (255, 255, 255), 2)\n",
    "        cv.line(image, tuple(landmark_point[15]), tuple(landmark_point[16]),\n",
    "                (0, 0, 0), 6)\n",
    "        cv.line(image, tuple(landmark_point[15]), tuple(landmark_point[16]),\n",
    "                (255, 255, 255), 2)\n",
    "\n",
    "        # Little finger\n",
    "        cv.line(image, tuple(landmark_point[17]), tuple(landmark_point[18]),\n",
    "                (0, 0, 0), 6)\n",
    "        cv.line(image, tuple(landmark_point[17]), tuple(landmark_point[18]),\n",
    "                (255, 255, 255), 2)\n",
    "        cv.line(image, tuple(landmark_point[18]), tuple(landmark_point[19]),\n",
    "                (0, 0, 0), 6)\n",
    "        cv.line(image, tuple(landmark_point[18]), tuple(landmark_point[19]),\n",
    "                (255, 255, 255), 2)\n",
    "        cv.line(image, tuple(landmark_point[19]), tuple(landmark_point[20]),\n",
    "                (0, 0, 0), 6)\n",
    "        cv.line(image, tuple(landmark_point[19]), tuple(landmark_point[20]),\n",
    "                (255, 255, 255), 2)\n",
    "\n",
    "        # Palm\n",
    "        cv.line(image, tuple(landmark_point[0]), tuple(landmark_point[1]),\n",
    "                (0, 0, 0), 6)\n",
    "        cv.line(image, tuple(landmark_point[0]), tuple(landmark_point[1]),\n",
    "                (255, 255, 255), 2)\n",
    "        cv.line(image, tuple(landmark_point[1]), tuple(landmark_point[2]),\n",
    "                (0, 0, 0), 6)\n",
    "        cv.line(image, tuple(landmark_point[1]), tuple(landmark_point[2]),\n",
    "                (255, 255, 255), 2)\n",
    "        cv.line(image, tuple(landmark_point[2]), tuple(landmark_point[5]),\n",
    "                (0, 0, 0), 6)\n",
    "        cv.line(image, tuple(landmark_point[2]), tuple(landmark_point[5]),\n",
    "                (255, 255, 255), 2)\n",
    "        cv.line(image, tuple(landmark_point[5]), tuple(landmark_point[9]),\n",
    "                (0, 0, 0), 6)\n",
    "        cv.line(image, tuple(landmark_point[5]), tuple(landmark_point[9]),\n",
    "                (255, 255, 255), 2)\n",
    "        cv.line(image, tuple(landmark_point[9]), tuple(landmark_point[13]),\n",
    "                (0, 0, 0), 6)\n",
    "        cv.line(image, tuple(landmark_point[9]), tuple(landmark_point[13]),\n",
    "                (255, 255, 255), 2)\n",
    "        cv.line(image, tuple(landmark_point[13]), tuple(landmark_point[17]),\n",
    "                (0, 0, 0), 6)\n",
    "        cv.line(image, tuple(landmark_point[13]), tuple(landmark_point[17]),\n",
    "                (255, 255, 255), 2)\n",
    "        cv.line(image, tuple(landmark_point[17]), tuple(landmark_point[0]),\n",
    "                (0, 0, 0), 6)\n",
    "        cv.line(image, tuple(landmark_point[17]), tuple(landmark_point[0]),\n",
    "                (255, 255, 255), 2)\n",
    "\n",
    "    # Key Points\n",
    "    for index, landmark in enumerate(landmark_point):\n",
    "        if index == 0:  \n",
    "            cv.circle(image, (landmark[0], landmark[1]), 5, (255, 255, 255),\n",
    "                      -1)\n",
    "            cv.circle(image, (landmark[0], landmark[1]), 5, (0, 0, 0), 1)\n",
    "        if index == 1:  \n",
    "            cv.circle(image, (landmark[0], landmark[1]), 5, (255, 255, 255),\n",
    "                      -1)\n",
    "            cv.circle(image, (landmark[0], landmark[1]), 5, (0, 0, 0), 1)\n",
    "        if index == 2:  \n",
    "            cv.circle(image, (landmark[0], landmark[1]), 5, (255, 255, 255),\n",
    "                      -1)\n",
    "            cv.circle(image, (landmark[0], landmark[1]), 5, (0, 0, 0), 1)\n",
    "        if index == 3:  \n",
    "            cv.circle(image, (landmark[0], landmark[1]), 5, (255, 255, 255),\n",
    "                      -1)\n",
    "            cv.circle(image, (landmark[0], landmark[1]), 5, (0, 0, 0), 1)\n",
    "        if index == 4:  \n",
    "            cv.circle(image, (landmark[0], landmark[1]), 8, (255, 255, 255),\n",
    "                      -1)\n",
    "            cv.circle(image, (landmark[0], landmark[1]), 8, (0, 0, 0), 1)\n",
    "        if index == 5:  \n",
    "            cv.circle(image, (landmark[0], landmark[1]), 5, (255, 255, 255),\n",
    "                      -1)\n",
    "            cv.circle(image, (landmark[0], landmark[1]), 5, (0, 0, 0), 1)\n",
    "        if index == 6:  \n",
    "            cv.circle(image, (landmark[0], landmark[1]), 5, (255, 255, 255),\n",
    "                      -1)\n",
    "            cv.circle(image, (landmark[0], landmark[1]), 5, (0, 0, 0), 1)\n",
    "        if index == 7:  \n",
    "            cv.circle(image, (landmark[0], landmark[1]), 5, (255, 255, 255),\n",
    "                      -1)\n",
    "            cv.circle(image, (landmark[0], landmark[1]), 5, (0, 0, 0), 1)\n",
    "        if index == 8:  \n",
    "            cv.circle(image, (landmark[0], landmark[1]), 8, (255, 255, 255),\n",
    "                      -1)\n",
    "            cv.circle(image, (landmark[0], landmark[1]), 8, (0, 0, 0), 1)\n",
    "        if index == 9:  \n",
    "            cv.circle(image, (landmark[0], landmark[1]), 5, (255, 255, 255),\n",
    "                      -1)\n",
    "            cv.circle(image, (landmark[0], landmark[1]), 5, (0, 0, 0), 1)\n",
    "        if index == 10:  \n",
    "            cv.circle(image, (landmark[0], landmark[1]), 5, (255, 255, 255),\n",
    "                      -1)\n",
    "            cv.circle(image, (landmark[0], landmark[1]), 5, (0, 0, 0), 1)\n",
    "        if index == 11:  \n",
    "            cv.circle(image, (landmark[0], landmark[1]), 5, (255, 255, 255),\n",
    "                      -1)\n",
    "            cv.circle(image, (landmark[0], landmark[1]), 5, (0, 0, 0), 1)\n",
    "        if index == 12:  \n",
    "            cv.circle(image, (landmark[0], landmark[1]), 8, (255, 255, 255),\n",
    "                      -1)\n",
    "            cv.circle(image, (landmark[0], landmark[1]), 8, (0, 0, 0), 1)\n",
    "        if index == 13:  \n",
    "            cv.circle(image, (landmark[0], landmark[1]), 5, (255, 255, 255),\n",
    "                      -1)\n",
    "            cv.circle(image, (landmark[0], landmark[1]), 5, (0, 0, 0), 1)\n",
    "        if index == 14:  \n",
    "            cv.circle(image, (landmark[0], landmark[1]), 5, (255, 255, 255),\n",
    "                      -1)\n",
    "            cv.circle(image, (landmark[0], landmark[1]), 5, (0, 0, 0), 1)\n",
    "        if index == 15:  \n",
    "            cv.circle(image, (landmark[0], landmark[1]), 5, (255, 255, 255),\n",
    "                      -1)\n",
    "            cv.circle(image, (landmark[0], landmark[1]), 5, (0, 0, 0), 1)\n",
    "        if index == 16:  \n",
    "            cv.circle(image, (landmark[0], landmark[1]), 8, (255, 255, 255),\n",
    "                      -1)\n",
    "            cv.circle(image, (landmark[0], landmark[1]), 8, (0, 0, 0), 1)\n",
    "        if index == 17:  \n",
    "            cv.circle(image, (landmark[0], landmark[1]), 5, (255, 255, 255),\n",
    "                      -1)\n",
    "            cv.circle(image, (landmark[0], landmark[1]), 5, (0, 0, 0), 1)\n",
    "        if index == 18:  \n",
    "            cv.circle(image, (landmark[0], landmark[1]), 5, (255, 255, 255),\n",
    "                      -1)\n",
    "            cv.circle(image, (landmark[0], landmark[1]), 5, (0, 0, 0), 1)\n",
    "        if index == 19:  \n",
    "            cv.circle(image, (landmark[0], landmark[1]), 5, (255, 255, 255),\n",
    "                      -1)\n",
    "            cv.circle(image, (landmark[0], landmark[1]), 5, (0, 0, 0), 1)\n",
    "        if index == 20:  \n",
    "            cv.circle(image, (landmark[0], landmark[1]), 8, (255, 255, 255),\n",
    "                      -1)\n",
    "            cv.circle(image, (landmark[0], landmark[1]), 8, (0, 0, 0), 1)\n",
    "\n",
    "    return image\n",
    "\n",
    "\n",
    "def draw_bounding_rect(use_brect, image, brect):\n",
    "    if use_brect:\n",
    "        # Outer rectangle\n",
    "        cv.rectangle(image, (brect[0], brect[1]), (brect[2], brect[3]),\n",
    "                     (0, 0, 0), 1)\n",
    "\n",
    "    return image\n",
    "\n",
    "\n",
    "def draw_info_text(image, brect, handedness, hand_sign_text,\n",
    "                   finger_gesture_text):\n",
    "    cv.rectangle(image, (brect[0], brect[1]), (brect[2], brect[1] - 22),\n",
    "                 (0, 0, 0), -1)\n",
    "\n",
    "    info_text = handedness.classification[0].label[0:]\n",
    "    if hand_sign_text != \"\":\n",
    "        info_text = info_text + ':' + hand_sign_text\n",
    "    cv.putText(image, info_text, (brect[0] + 5, brect[1] - 4),\n",
    "               cv.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1, cv.LINE_AA)\n",
    "\n",
    "    # if finger_gesture_text != \"\":\n",
    "    #     cv.putText(image, \"Finger Gesture:\" + finger_gesture_text, (10, 60),\n",
    "    #                cv.FONT_HERSHEY_SIMPLEX, 1.0, (0, 0, 0), 4, cv.LINE_AA)\n",
    "    #     cv.putText(image, \"Finger Gesture:\" + finger_gesture_text, (10, 60),\n",
    "    #                cv.FONT_HERSHEY_SIMPLEX, 1.0, (255, 255, 255), 2,\n",
    "    #                cv.LINE_AA)\n",
    "\n",
    "    return image\n",
    "\n",
    "\n",
    "def draw_point_history(image, point_history):\n",
    "    for index, point in enumerate(point_history):\n",
    "        if point[0] != 0 and point[1] != 0:\n",
    "            cv.circle(image, (point[0], point[1]), 1 + int(index / 2),\n",
    "                      (152, 251, 152), 2)\n",
    "\n",
    "    return image\n",
    "\n",
    "\n",
    "def draw_info(image, fps, mode, number):\n",
    "    cv.putText(image, \"FPS:\" + str(fps), (10, 30), cv.FONT_HERSHEY_SIMPLEX,\n",
    "               1.0, (0, 0, 0), 4, cv.LINE_AA)\n",
    "    cv.putText(image, \"FPS:\" + str(fps), (10, 30), cv.FONT_HERSHEY_SIMPLEX,\n",
    "               1.0, (255, 255, 255), 2, cv.LINE_AA)\n",
    "\n",
    "    mode_string = ['Logging Key Point', 'Logging Point History']\n",
    "    if 1 <= mode <= 2:\n",
    "        cv.putText(image, \"MODE:\" + mode_string[mode - 1], (10, 90),\n",
    "                   cv.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1,\n",
    "                   cv.LINE_AA)\n",
    "        if 0 <= number <= 9:\n",
    "            cv.putText(image, \"NUM:\" + str(number), (10, 110),\n",
    "                       cv.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1,\n",
    "                       cv.LINE_AA)\n",
    "    return image\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
